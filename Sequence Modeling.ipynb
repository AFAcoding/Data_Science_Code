{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence modelling \n",
    "\n",
    "## Coding tutorials\n",
    " #### [1.  The IMDb dataset](#coding_tutorial_1)\n",
    " #### [2. Padding and masking sequence data](#coding_tutorial_2)\n",
    " #### [3. The Embedding layer](#coding_tutorial_3)\n",
    " #### [4. The Embedding Projector](#coding_tutorial_4)\n",
    " #### [5. Recurrent neural network layers](#coding_tutorial_5)\n",
    " #### [6. Stacked RNNs and the Bidirectional wrapper](#coding_tutorial_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## The IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import imdb\n",
    "import tensorflow.keras.datasets.imdb as imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and assign the data set using load_data()\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the type of the data\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the data\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element input\n",
    "# Notice encoding\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element output\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset with different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with defaults\n",
    "imdb.load_data(path='imbd.npz',\n",
    "              index_from=3)\n",
    "\n",
    "# ~/.keras/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 2, 8, 118, 2, 14, 394, 20, 13, 119, 2, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 2, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 2, 7, 2, 2, 349, 2, 148, 2, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 2, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 2, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 2, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 2, 2, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 2, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 2, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 2, 116, 2, 2, 13, 191, 79, 2, 89, 2, 14, 9, 8, 106, 2, 2, 35, 2, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 2, 84, 2, 325, 2, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 2, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 2, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 2, 108, 45, 40, 29, 2, 395, 11, 6, 2, 2, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 2, 443, 2, 5, 27, 2, 117, 2, 2, 165, 47, 84, 37, 131, 2, 14, 2, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 2, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 2, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 2, 2, 372, 2, 2, 2, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
       "         list([1, 2, 2, 69, 72, 2, 13, 2, 2, 8, 12, 2, 23, 5, 16, 484, 2, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 2, 32, 61, 369, 71, 66, 2, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 2, 75, 2, 44, 257, 390, 5, 69, 263, 2, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 2, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 2, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 2, 25, 8, 2, 12, 145, 5, 202, 12, 160, 2, 202, 12, 6, 52, 58, 2, 92, 401, 2, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 2, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 2, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 2, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 2, 5, 383, 2, 2, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 2, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 2, 202, 14, 31, 6, 2, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 2]),\n",
       "         list([1, 14, 22, 2, 6, 176, 7, 2, 88, 12, 2, 23, 2, 5, 109, 2, 4, 114, 9, 55, 2, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2, 109, 2, 21, 4, 22, 2, 8, 6, 2, 2, 10, 10, 4, 105, 2, 35, 2, 2, 19, 2, 2, 5, 2, 2, 45, 55, 221, 15, 2, 2, 2, 14, 2, 4, 405, 5, 2, 7, 27, 85, 108, 131, 4, 2, 2, 2, 405, 9, 2, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 2, 239, 34, 2, 2, 45, 407, 31, 7, 41, 2, 105, 21, 59, 299, 12, 38, 2, 5, 2, 15, 45, 2, 488, 2, 127, 6, 52, 292, 17, 4, 2, 185, 132, 2, 2, 2, 488, 2, 47, 6, 392, 173, 4, 2, 2, 270, 2, 4, 2, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 2, 2, 7, 2, 2, 2, 5, 2, 30, 2, 2, 56, 4, 2, 5, 2, 2, 8, 4, 2, 398, 229, 10, 10, 13, 2, 2, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2, 19, 2, 2, 2, 2, 14, 22, 9, 2, 21, 45, 2, 5, 45, 252, 8, 2, 6, 2, 2, 2, 39, 4, 2, 48, 25, 181, 8, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 2, 8, 169, 11, 374, 2, 25, 203, 28, 8, 2, 12, 125, 4, 2]),\n",
       "         list([1, 111, 2, 2, 2, 2, 2, 4, 87, 2, 2, 7, 31, 318, 2, 7, 4, 498, 2, 2, 63, 29, 2, 220, 2, 2, 5, 17, 12, 2, 220, 2, 17, 6, 185, 132, 2, 16, 53, 2, 11, 2, 74, 4, 438, 21, 27, 2, 2, 8, 22, 107, 2, 2, 2, 2, 8, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 5, 2, 98, 31, 2, 33, 6, 58, 14, 2, 2, 8, 4, 365, 7, 2, 2, 356, 346, 4, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 2, 431, 2, 7, 32, 2, 16, 11, 94, 2, 10, 10, 4, 2, 2, 7, 4, 2, 2, 2, 2, 8, 2, 8, 2, 121, 31, 7, 27, 86, 2, 2, 16, 6, 465, 2, 2, 2, 2, 17, 2, 42, 4, 2, 37, 473, 6, 2, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 2, 2, 53, 33, 2, 2, 37, 70, 2, 4, 2, 2, 74, 476, 37, 62, 91, 2, 169, 4, 2, 2, 146, 2, 2, 5, 258, 12, 184, 2, 2, 5, 2, 2, 7, 4, 22, 2, 18, 2, 2, 2, 7, 4, 2, 71, 348, 425, 2, 2, 19, 2, 5, 2, 11, 2, 8, 339, 2, 4, 2, 2, 7, 4, 2, 10, 10, 263, 2, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 2, 19, 68, 2, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 2, 2, 36, 2, 8, 2, 2, 18, 6, 2, 4, 2, 26, 2, 2, 11, 14, 2, 2, 12, 426, 28, 77, 2, 8, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 9, 2, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2, 247, 30, 2, 6, 2, 54, 2, 2, 98, 6, 2, 40, 2, 37, 2, 98, 4, 2, 2, 15, 14, 9, 57, 2, 5, 2, 6, 275, 2, 2, 2, 2, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 2, 37, 2, 2, 98, 4, 2, 2, 90, 19, 6, 2, 7, 2, 2, 2, 4, 2, 2, 2, 8, 2, 90, 4, 2, 8, 4, 2, 17, 2, 2, 2, 4, 2, 8, 2, 189, 4, 2, 2, 2, 4, 2, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 2, 6, 425, 2, 2, 2, 2, 7, 4, 2, 2, 469, 4, 2, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 5, 2, 68, 2, 19, 2, 2, 4, 2, 7, 263, 65, 2, 34, 6, 2, 2, 43, 159, 29, 9, 2, 9, 387, 73, 195, 2, 10, 10, 2, 4, 58, 2, 54, 14, 2, 117, 22, 16, 93, 5, 2, 4, 192, 15, 12, 16, 93, 34, 6, 2, 2, 33, 4, 2, 7, 15, 2, 2, 2, 325, 12, 62, 30, 2, 8, 67, 14, 17, 6, 2, 44, 148, 2, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 2, 2, 27, 2, 7, 2, 4, 22, 2, 17, 6, 2, 2, 7, 2, 2, 2, 100, 30, 4, 2, 2, 2, 2, 42, 2, 11, 4, 2, 42, 101, 2, 7, 101, 2, 15, 2, 94, 2, 180, 5, 9, 2, 34, 2, 45, 6, 2, 22, 60, 6, 2, 31, 11, 94, 2, 96, 21, 94, 2, 9, 57, 2]),\n",
       "         ...,\n",
       "         list([1, 13, 2, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 2, 2, 2, 2, 2, 395, 2, 5, 2, 11, 119, 2, 89, 2, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2, 284, 2, 2, 37, 315, 4, 226, 20, 272, 2, 40, 29, 152, 60, 181, 8, 30, 50, 2, 362, 80, 119, 12, 21, 2, 2]),\n",
       "         list([1, 11, 119, 241, 9, 4, 2, 20, 12, 468, 15, 94, 2, 2, 2, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2, 7, 2, 46, 2, 9, 2, 5, 4, 2, 47, 8, 79, 90, 145, 164, 162, 50, 6, 2, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 2, 200, 5, 2, 5, 9, 2, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 2, 13, 2, 14, 20, 6, 2, 7, 470]),\n",
       "         list([1, 6, 52, 2, 430, 22, 9, 220, 2, 8, 28, 2, 2, 2, 6, 2, 15, 47, 6, 2, 2, 8, 114, 5, 33, 222, 31, 55, 184, 2, 2, 2, 19, 346, 2, 5, 6, 364, 350, 4, 184, 2, 9, 133, 2, 11, 2, 2, 21, 4, 2, 2, 2, 50, 2, 2, 9, 6, 2, 17, 6, 2, 2, 21, 17, 6, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 2, 19, 4, 78, 173, 7, 27, 2, 2, 2, 2, 2, 9, 6, 2, 17, 210, 5, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 2, 7, 4, 314, 74, 6, 2, 22, 2, 19, 2, 2, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 2, 2, 2, 4, 2, 25, 124, 4, 31, 12, 16, 93, 2, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the vocabulary to the top 500 words using num_words\n",
    "imdb.load_data(num_words=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([2, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 2, 173, 36, 256, 2, 25, 100, 43, 838, 112, 50, 670, 2, 2, 35, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 39, 2, 172, 2, 2, 17, 546, 38, 13, 447, 2, 192, 50, 16, 2, 147, 2, 19, 14, 22, 2, 2, 2, 469, 2, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 2, 22, 17, 515, 17, 12, 16, 626, 18, 2, 2, 62, 386, 12, 2, 316, 2, 106, 2, 2, 2, 2, 16, 480, 66, 2, 33, 2, 130, 12, 16, 38, 619, 2, 25, 124, 51, 36, 135, 48, 25, 2, 33, 2, 22, 12, 215, 28, 77, 52, 2, 14, 407, 16, 82, 2, 2, 2, 107, 117, 2, 15, 256, 2, 2, 2, 2, 2, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 2, 2, 2, 2, 13, 104, 88, 2, 381, 15, 297, 98, 32, 2, 56, 26, 141, 2, 194, 2, 18, 2, 226, 22, 21, 134, 476, 26, 480, 2, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 2, 226, 65, 16, 38, 2, 88, 12, 16, 283, 2, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([2, 194, 2, 194, 2, 78, 228, 2, 2, 2, 2, 2, 134, 26, 2, 715, 2, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 2, 207, 110, 2, 21, 14, 69, 188, 2, 30, 23, 2, 2, 249, 126, 93, 2, 114, 2, 2, 2, 2, 647, 2, 116, 2, 35, 2, 2, 229, 2, 340, 2, 2, 118, 2, 2, 130, 2, 19, 2, 2, 2, 89, 29, 952, 46, 37, 2, 455, 2, 45, 43, 38, 2, 2, 398, 2, 2, 26, 2, 2, 163, 11, 2, 2, 2, 2, 2, 194, 775, 2, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 2, 2, 228, 2, 43, 2, 2, 15, 299, 120, 2, 120, 174, 11, 220, 175, 136, 50, 2, 2, 228, 2, 2, 2, 656, 245, 2, 2, 2, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 2, 2, 371, 78, 22, 625, 64, 2, 2, 2, 168, 145, 23, 2, 2, 15, 16, 2, 2, 2, 28, 2, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([2, 14, 47, 2, 30, 31, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 2, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 2, 86, 320, 35, 534, 19, 263, 2, 2, 2, 2, 33, 89, 78, 12, 66, 16, 2, 360, 2, 2, 58, 316, 334, 11, 2, 2, 43, 645, 662, 2, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 2, 106, 14, 2, 2, 18, 2, 22, 12, 215, 28, 610, 40, 2, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 2, 22, 47, 2, 2, 51, 2, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 2, 2, 106, 607, 624, 35, 534, 2, 227, 2, 129, 113]),\n",
       "         ...,\n",
       "         list([2, 11, 2, 230, 245, 2, 2, 2, 2, 446, 2, 45, 2, 84, 2, 2, 21, 2, 912, 84, 2, 325, 725, 134, 2, 2, 84, 2, 36, 28, 57, 2, 21, 2, 140, 2, 703, 2, 2, 84, 56, 18, 2, 14, 2, 31, 2, 2, 2, 2, 2, 2, 2, 18, 2, 20, 207, 110, 563, 12, 2, 2, 2, 2, 97, 2, 20, 53, 2, 74, 2, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 2, 2, 500, 2, 2, 89, 364, 70, 29, 140, 2, 64, 2, 11, 2, 2, 26, 178, 2, 529, 443, 2, 2, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 2, 65, 496, 2, 231, 2, 790, 2, 2, 320, 234, 2, 234, 2, 2, 2, 496, 2, 139, 929, 2, 2, 2, 2, 2, 18, 2, 2, 2, 250, 11, 2, 2, 2, 2, 2, 747, 2, 372, 2, 2, 541, 2, 2, 2, 59, 2, 2, 2, 2]),\n",
       "         list([2, 2, 2, 69, 72, 2, 13, 610, 930, 2, 12, 582, 23, 2, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 2, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 2, 2, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 2, 69, 263, 514, 105, 50, 286, 2, 23, 2, 123, 13, 161, 40, 2, 421, 2, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 2, 719, 2, 13, 18, 31, 62, 40, 2, 2, 2, 2, 2, 14, 123, 2, 942, 25, 2, 721, 12, 145, 2, 202, 12, 160, 580, 202, 12, 2, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 2, 15, 251, 2, 2, 12, 38, 84, 80, 124, 12, 2, 23]),\n",
       "         list([2, 17, 2, 194, 337, 2, 2, 204, 22, 45, 254, 2, 106, 14, 123, 2, 2, 270, 2, 2, 2, 2, 732, 2, 101, 405, 39, 14, 2, 2, 2, 2, 115, 50, 305, 12, 47, 2, 168, 2, 235, 2, 38, 111, 699, 102, 2, 2, 2, 2, 2, 24, 2, 78, 2, 17, 2, 2, 21, 27, 2, 2, 2, 2, 2, 92, 2, 2, 2, 2, 2, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 2, 97, 12, 157, 21, 2, 2, 2, 2, 66, 78, 2, 2, 631, 2, 2, 2, 272, 191, 2, 2, 2, 2, 2, 2, 2, 544, 2, 383, 2, 848, 2, 2, 497, 2, 2, 2, 2, 2, 21, 60, 27, 239, 2, 43, 2, 209, 405, 10, 10, 12, 764, 40, 2, 248, 20, 12, 16, 2, 174, 2, 72, 2, 51, 2, 2, 22, 2, 204, 131, 2])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([2, 591, 202, 14, 31, 2, 717, 10, 10, 2, 2, 2, 2, 360, 2, 2, 177, 2, 394, 354, 2, 123, 2, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 2, 124, 14, 286, 170, 2, 157, 46, 2, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 2, 717]),\n",
       "         list([2, 14, 22, 2, 2, 176, 2, 2, 88, 12, 2, 23, 2, 2, 109, 943, 2, 114, 2, 55, 606, 2, 111, 2, 2, 139, 193, 273, 23, 2, 172, 270, 11, 2, 2, 2, 2, 2, 109, 2, 21, 2, 22, 2, 2, 2, 2, 2, 10, 10, 2, 105, 987, 35, 841, 2, 19, 861, 2, 2, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 2, 405, 2, 2, 2, 27, 85, 108, 131, 2, 2, 2, 2, 405, 2, 2, 133, 2, 50, 13, 104, 51, 66, 166, 14, 22, 157, 2, 2, 530, 239, 34, 2, 2, 45, 407, 31, 2, 41, 2, 105, 21, 59, 299, 12, 38, 950, 2, 2, 15, 45, 629, 488, 2, 127, 2, 52, 292, 17, 2, 2, 185, 132, 2, 2, 2, 488, 2, 47, 2, 392, 173, 2, 2, 2, 270, 2, 2, 2, 2, 2, 65, 55, 73, 11, 346, 14, 20, 2, 2, 976, 2, 2, 2, 861, 2, 2, 2, 30, 2, 2, 56, 2, 841, 2, 990, 692, 2, 2, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 2, 31, 2, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 2, 2, 21, 45, 2, 2, 45, 252, 2, 2, 2, 565, 921, 2, 39, 2, 529, 48, 25, 181, 2, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 2, 290, 2, 58, 10, 10, 472, 45, 55, 878, 2, 169, 11, 374, 2, 25, 203, 28, 2, 818, 12, 125, 2, 2]),\n",
       "         list([2, 111, 748, 2, 2, 2, 2, 2, 87, 2, 2, 2, 31, 318, 2, 2, 2, 498, 2, 748, 63, 29, 2, 220, 686, 2, 2, 17, 12, 575, 220, 2, 17, 2, 185, 132, 2, 16, 53, 928, 11, 2, 74, 2, 438, 21, 27, 2, 589, 2, 22, 107, 2, 2, 997, 2, 2, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 2, 2, 98, 31, 2, 33, 2, 58, 14, 2, 2, 2, 2, 365, 2, 2, 2, 356, 346, 2, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 2, 58, 54, 2, 431, 748, 2, 32, 2, 16, 11, 94, 2, 10, 10, 2, 993, 2, 2, 2, 2, 2, 2, 2, 2, 847, 2, 2, 121, 31, 2, 27, 86, 2, 2, 16, 2, 465, 993, 2, 2, 573, 17, 2, 42, 2, 2, 37, 473, 2, 711, 2, 2, 2, 328, 212, 70, 30, 258, 11, 220, 32, 2, 108, 21, 133, 12, 2, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 2, 2, 2, 74, 476, 37, 62, 91, 2, 169, 2, 2, 2, 146, 655, 2, 2, 258, 12, 184, 2, 546, 2, 849, 2, 2, 2, 22, 2, 18, 631, 2, 797, 2, 2, 2, 71, 348, 425, 2, 2, 19, 2, 2, 2, 11, 661, 2, 339, 2, 2, 2, 2, 2, 2, 2, 10, 10, 263, 787, 2, 270, 11, 2, 2, 2, 2, 2, 121, 2, 2, 26, 2, 19, 68, 2, 2, 28, 446, 2, 318, 2, 2, 67, 51, 36, 70, 81, 2, 2, 2, 36, 2, 2, 2, 2, 18, 2, 711, 2, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 2, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 2, 2, 17, 2, 2, 428, 2, 232, 11, 2, 2, 37, 272, 40, 2, 247, 30, 656, 2, 2, 54, 2, 2, 98, 2, 2, 40, 558, 37, 2, 98, 2, 2, 2, 15, 14, 2, 57, 2, 2, 2, 2, 275, 711, 2, 2, 2, 98, 2, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 2, 2, 2, 90, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 930, 2, 508, 90, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 2, 189, 2, 2, 2, 2, 2, 2, 2, 95, 271, 23, 2, 2, 2, 2, 2, 33, 2, 2, 425, 2, 2, 2, 2, 2, 2, 2, 2, 469, 2, 2, 54, 2, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 2, 2, 68, 2, 19, 2, 2, 2, 2, 2, 263, 65, 2, 34, 2, 2, 2, 43, 159, 29, 2, 2, 2, 387, 73, 195, 584, 10, 10, 2, 2, 58, 810, 54, 14, 2, 117, 22, 16, 93, 2, 2, 2, 192, 15, 12, 16, 93, 34, 2, 2, 2, 33, 2, 2, 2, 15, 2, 2, 2, 325, 12, 62, 30, 776, 2, 67, 14, 17, 2, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 2, 819, 2, 22, 2, 17, 2, 2, 787, 2, 2, 2, 2, 100, 30, 2, 2, 2, 2, 2, 42, 2, 11, 2, 2, 42, 101, 704, 2, 101, 999, 15, 2, 94, 2, 180, 2, 2, 2, 34, 2, 45, 2, 2, 22, 60, 2, 2, 31, 11, 94, 2, 96, 21, 94, 749, 2, 57, 975]),\n",
       "         ...,\n",
       "         list([2, 13, 2, 15, 2, 135, 14, 2, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 2, 2, 910, 769, 2, 2, 395, 2, 2, 2, 11, 119, 2, 89, 2, 2, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 2, 185, 2, 284, 2, 2, 37, 315, 2, 226, 20, 272, 2, 40, 29, 152, 60, 181, 2, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([2, 11, 119, 241, 2, 2, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 2, 86, 107, 2, 97, 14, 31, 33, 2, 2, 2, 743, 46, 2, 2, 2, 2, 2, 768, 47, 2, 79, 90, 145, 164, 162, 50, 2, 501, 119, 2, 2, 2, 78, 232, 15, 16, 224, 11, 2, 333, 20, 2, 985, 200, 2, 2, 2, 2, 2, 2, 79, 357, 2, 20, 47, 220, 57, 206, 139, 11, 12, 2, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 2, 2, 2, 470]),\n",
       "         list([2, 2, 52, 2, 430, 22, 2, 220, 2, 2, 28, 2, 519, 2, 2, 769, 15, 47, 2, 2, 2, 2, 114, 2, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 2, 2, 364, 350, 2, 184, 2, 2, 133, 2, 11, 2, 2, 21, 2, 2, 2, 570, 50, 2, 2, 2, 2, 2, 17, 2, 2, 2, 21, 17, 2, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 2, 194, 21, 29, 218, 2, 19, 2, 78, 173, 2, 27, 2, 2, 2, 718, 2, 2, 2, 2, 17, 210, 2, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 2, 392, 217, 21, 50, 2, 57, 65, 12, 2, 53, 40, 35, 390, 2, 11, 2, 2, 2, 2, 314, 74, 2, 792, 22, 2, 19, 714, 727, 2, 382, 2, 91, 2, 439, 19, 14, 20, 2, 2, 2, 2, 2, 756, 25, 124, 2, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore the top 10 most frequent words using skip_top\n",
    "imdb.load_data(skip_top=10,num_words=1000,oov_char=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 518, 21, 55, 1713, 6, 20, 716, 6, 65, 38, 73, 15, 12, 220, 461, 878, 14, 20, 716, 450, 537, 38, 73, 5189, 15, 12, 16, 4, 86, 171, 211, 6, 20, 13, 100, 24, 106, 8, 20252, 12, 16, 99, 147, 5, 4, 105, 38, 565, 15, 149, 12, 877, 6, 965, 1651, 319, 134, 289, 349, 5, 68, 2166, 855, 19, 68, 10082, 31, 11, 843, 400, 569, 72, 99, 254, 150, 13, 28, 296, 11, 94, 6274, 209, 21501, 450, 211, 5, 13, 923, 51, 13, 210, 6677, 14, 20, 9, 6, 991, 4, 487, 4, 116, 4, 10409, 7, 450, 537, 209, 112, 60, 4, 222, 227, 5303, 285, 44, 14, 20, 9, 3160, 1542, 1809, 2128, 57, 594, 12, 434, 215, 28, 1816, 98]),\n",
       "         list([1, 14, 22, 714, 8012, 4, 921, 2124, 4, 905, 1488, 5, 4, 350, 2501, 354, 7, 1691, 1612, 349, 13, 1610, 12, 23, 6, 13574, 5, 16, 2664, 15, 13, 69, 24, 557, 7, 12, 159, 10, 10, 13, 81, 24, 124, 48, 14, 16, 14513, 3667, 2016, 21, 4, 1794, 4, 8466, 5, 943, 7, 4, 105, 17, 73, 17, 4, 49, 1096, 370, 157, 3392, 4, 109, 33241, 299, 32, 1467, 6, 1249, 744, 10, 10, 4, 8466, 200, 1593, 5, 14513, 1367, 4, 172, 389, 1175, 75, 219, 11, 1513, 890, 19, 1593, 5, 1441, 6909, 6239, 9, 389, 11, 41, 105, 1302, 4182, 5, 13291, 6, 8022, 23, 41, 105, 11, 33, 297, 11, 4, 5322, 7, 4, 1635, 59, 9, 2227, 5, 246, 31, 70, 9530, 19, 41, 33, 4, 172, 58, 10, 10, 50, 26, 49, 388, 121, 13, 235, 4, 114, 9281, 6, 1229, 5, 4, 388, 200, 33241, 5, 27, 1233, 980, 220, 306, 398, 18, 160, 22, 33241, 266, 125, 17, 160, 109, 32, 295, 21, 148, 26, 1403, 5266, 10, 10, 14, 22, 215, 30, 448, 23, 6, 283, 65, 42, 215, 28, 77, 398, 34, 294, 37, 1452, 134, 2490, 13, 967, 12, 709, 46, 7, 6, 878, 158, 10, 10]),\n",
       "         list([1, 13, 219, 14, 20, 23, 248, 5, 447, 12, 13, 244, 6, 147, 1690, 22, 337, 5, 14, 31, 16, 87, 4, 177, 16, 93, 7, 49, 66, 221, 84, 8246, 9, 210, 87, 5, 1024, 31711, 9, 11, 6, 2756, 7, 27, 205, 29, 70, 297, 199, 212, 5, 708, 11, 4, 172, 20, 40, 171, 409, 70, 4, 65, 347, 9, 87, 99, 4, 197, 7, 112, 502, 8, 794, 6, 58, 347, 7, 51, 80, 593, 5, 8, 361, 14, 58, 347, 8, 3621, 6, 4564, 1690, 9, 35, 221, 326, 5, 14, 20, 961, 12, 46, 11, 141, 6, 96, 15, 9, 220, 484, 867])],\n",
       "        dtype=object), array([1, 0, 0, ..., 1, 1, 1])),\n",
       " (array([list([1, 14, 9, 31, 7, 4, 249, 108, 13, 28, 110, 11, 6, 137, 10, 10, 4, 439, 9, 15, 12, 152, 124, 726, 12, 494, 8, 30, 35, 1089, 993, 22, 43675, 42, 35, 3435, 9, 10528, 17, 6, 959, 12, 996, 23, 32, 6566, 10, 10, 4, 116, 9, 2526, 4, 2559, 125, 1489, 5, 4, 424, 3881, 1149, 10, 10, 14746, 8035, 9, 242, 4, 118, 155, 44, 14, 22, 21, 15, 218, 6, 52, 155, 252, 29, 47, 35, 1596, 5, 61226, 168, 21, 1116, 29, 191, 165, 511, 43, 168, 33, 89, 29, 12482, 54, 27, 4727, 889, 10, 10, 66, 92, 106, 14, 22, 49, 135, 12, 738, 3260, 4719, 13, 135, 31, 9, 99, 111]),\n",
       "         list([1, 4, 7591, 248, 7, 108, 5077, 28, 13, 421, 38, 117, 11728, 8, 105, 5077, 28, 13, 77, 93, 8, 4032, 34, 141, 3648, 414, 15670, 1316, 3264, 7678, 28837, 2161, 8464, 2986, 732, 12435, 61019, 46432, 798, 14, 22, 17, 48, 12, 71, 129, 24558]),\n",
       "         list([1, 160, 12576, 212, 270, 11, 4, 1547, 12, 186, 15, 4, 612, 31, 1622, 1466, 18, 1205, 16, 11, 14, 172, 719, 1547, 17, 38, 111, 7, 12563, 5, 71375, 108, 26, 270, 50, 5, 137, 14, 9, 246, 160, 31, 12, 9, 275, 195, 5, 73, 93, 15, 13, 131, 510, 12, 10, 10, 16866, 9, 928, 11, 6, 1155, 74, 644, 267, 5, 116, 7376, 30258, 13, 104, 442, 424, 8, 30, 6, 117, 1155, 151, 11, 41, 3992, 523, 59, 9, 99, 185, 8, 30, 928, 11, 349, 73, 16866, 127, 24, 1497, 41, 1417, 5, 515, 29, 5, 7376, 521, 245, 18, 49, 1356, 253, 183, 79, 2732, 54, 4, 3992, 106, 9, 2586, 16866, 659, 12, 5, 408, 12, 8, 7376, 17, 6, 3470, 5, 111, 712, 959, 10, 10, 542, 1794, 5, 4, 192, 15, 14, 20, 122, 24, 5390, 99, 76, 23, 706, 2764, 21, 6, 3793, 114, 97, 14, 6, 1036, 5, 737, 117, 22]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 0, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the sequence lengths to 500 using maxlen\n",
    "imdb.load_data(maxlen=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use '1' as the character that indicates the start of a sequence\n",
    "\n",
    "imdb.load_data(start_char=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb word index using get_word_index()\n",
    "imdb_word_index=imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the word index as a dictionary,\n",
    "# accounting for index_from.\n",
    "index_from=3\n",
    "imdb_word_index={key:value + index_from for key,value in imdb_word_index.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a specific word's index\n",
    "imdb_word_index['simpsonian']\n",
    "imdb_word_index['the']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'film',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'casting',\n",
       " 'location',\n",
       " 'scenery',\n",
       " 'story',\n",
       " 'direction',\n",
       " \"everyone's\",\n",
       " 'really',\n",
       " 'suited',\n",
       " 'the',\n",
       " 'part',\n",
       " 'they',\n",
       " 'played',\n",
       " 'and',\n",
       " 'you',\n",
       " 'could',\n",
       " 'just',\n",
       " 'imagine',\n",
       " 'being',\n",
       " 'there',\n",
       " 'robert',\n",
       " \"redford's\",\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'same',\n",
       " 'being',\n",
       " 'director',\n",
       " \"norman's\",\n",
       " 'father',\n",
       " 'came',\n",
       " 'from',\n",
       " 'the',\n",
       " 'same',\n",
       " 'scottish',\n",
       " 'island',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'so',\n",
       " 'i',\n",
       " 'loved',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'real',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " 'the',\n",
       " 'witty',\n",
       " 'remarks',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'film',\n",
       " 'were',\n",
       " 'great',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'film',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'it',\n",
       " 'was',\n",
       " 'released',\n",
       " 'for',\n",
       " 'retail',\n",
       " 'and',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'it',\n",
       " 'to',\n",
       " 'everyone',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fly',\n",
       " 'fishing',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'really',\n",
       " 'cried',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'if',\n",
       " 'you',\n",
       " 'cry',\n",
       " 'at',\n",
       " 'a',\n",
       " 'film',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'good',\n",
       " 'and',\n",
       " 'this',\n",
       " 'definitely',\n",
       " 'was',\n",
       " 'also',\n",
       " 'congratulations',\n",
       " 'to',\n",
       " 'the',\n",
       " 'two',\n",
       " 'little',\n",
       " \"boy's\",\n",
       " 'that',\n",
       " 'played',\n",
       " 'the',\n",
       " \"part's\",\n",
       " 'of',\n",
       " 'norman',\n",
       " 'and',\n",
       " 'paul',\n",
       " 'they',\n",
       " 'were',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'children',\n",
       " 'are',\n",
       " 'often',\n",
       " 'left',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'praising',\n",
       " 'list',\n",
       " 'i',\n",
       " 'think',\n",
       " 'because',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'play',\n",
       " 'them',\n",
       " 'all',\n",
       " 'grown',\n",
       " 'up',\n",
       " 'are',\n",
       " 'such',\n",
       " 'a',\n",
       " 'big',\n",
       " 'profile',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'but',\n",
       " 'these',\n",
       " 'children',\n",
       " 'are',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'praised',\n",
       " 'for',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'think',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'story',\n",
       " 'was',\n",
       " 'so',\n",
       " 'lovely',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'true',\n",
       " 'and',\n",
       " 'was',\n",
       " \"someone's\",\n",
       " 'life',\n",
       " 'after',\n",
       " 'all',\n",
       " 'that',\n",
       " 'was',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View an input sentence\n",
    "inv_imdb_word_index={value:key for key,value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_train[0] if (index > index_from)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sentiment value\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Padding and Masking Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb data set\n",
    "(x_train,y_train),(x_test,y_test)=imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the input data shape\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the inputs to the maximum length using maxlen\n",
    "padded_x_train=tf.keras.preprocessing.sequence.pad_sequences(x_train,maxlen=300,padding='post',truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the output data shape\n",
    "padded_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   1],\n",
       "        [  14],\n",
       "        [  22],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       [[   1],\n",
       "        [ 194],\n",
       "        [1153],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       [[   1],\n",
       "        [  14],\n",
       "        [  47],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[   1],\n",
       "        [  11],\n",
       "        [   6],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       [[   1],\n",
       "        [1446],\n",
       "        [7079],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]],\n",
       "\n",
       "       [[   1],\n",
       "        [  17],\n",
       "        [   6],\n",
       "        ...,\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0]]], dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masking expects to see (batch, sequence, features)\n",
    "# Create a dummy feature dimension using expand_dims\n",
    "np.expand_dims(padded_x_train,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Masking layer \n",
    "tf_x_train=tf.convert_to_tensor(padded_x_train,dtype='float32')\n",
    "masking_layer=tf.keras.layers.Masking(mask_value=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass tf_x_train to it\n",
    "masked_x_train=masking_layer(tf_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1, shape=(25000, 300), dtype=float32, numpy=\n",
       "array([[1.000e+00, 1.400e+01, 2.200e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.940e+02, 1.153e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.400e+01, 4.700e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.000e+00, 1.100e+01, 6.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.446e+03, 7.079e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.700e+01, 6.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the dataset\n",
    "\n",
    "tf_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(25000, 300), dtype=float32, numpy=\n",
       "array([[1.000e+00, 1.400e+01, 2.200e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.940e+02, 1.153e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.400e+01, 4.700e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.000e+00, 1.100e+01, 6.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.446e+03, 7.079e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+00, 1.700e+01, 6.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the ._keras_mask for the dataset\n",
    "\n",
    "masked_x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer using layers.Embedding\n",
    "# Specify input_dim, output_dim, input_length\n",
    "\n",
    "embedding_layer=tf.keras.layers.Embedding(input_dim=501,output_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=42, shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
       "array([[[[ 0.02877263, -0.04866865, -0.03304682,  0.02090834,\n",
       "           0.02817264, -0.04651171,  0.02636207,  0.00802139,\n",
       "          -0.04460333, -0.02667554, -0.03484335,  0.0481918 ,\n",
       "          -0.0119465 ,  0.0368279 , -0.0464255 , -0.01884762]],\n",
       "\n",
       "        [[ 0.03232479, -0.02635177,  0.00085033,  0.0010885 ,\n",
       "          -0.00105834, -0.0044227 ,  0.01023115, -0.03281521,\n",
       "          -0.00310079, -0.03425016,  0.02943918, -0.04125081,\n",
       "           0.03420475, -0.04621635,  0.02661492,  0.01559437]],\n",
       "\n",
       "        [[-0.01185532, -0.02855587, -0.04319454,  0.03917933,\n",
       "           0.01989875, -0.02003735,  0.03057928,  0.02263938,\n",
       "          -0.03150371,  0.04510275,  0.01486105, -0.02033389,\n",
       "           0.00667509,  0.02130643, -0.04806541,  0.01863731]],\n",
       "\n",
       "        [[-0.04842912, -0.01314162, -0.01903698,  0.048715  ,\n",
       "           0.02070191, -0.02931442, -0.04257436,  0.00518801,\n",
       "          -0.00523872, -0.00680741,  0.01480624,  0.04694063,\n",
       "           0.03360529, -0.03364668, -0.04321274,  0.02449815]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an Embedding layer output for a fixed input\n",
    "# Expects an input of shape (batch, sequence, feature)\n",
    "\n",
    "sequence_of_indices=tf.constant([[[0],[1],[5],[500]]])\n",
    "sequences_of_embeddings=embedding_layer(sequence_of_indices)\n",
    "sequences_of_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02877263, -0.04866865, -0.03304682, ...,  0.0368279 ,\n",
       "        -0.0464255 , -0.01884762],\n",
       "       [ 0.03232479, -0.02635177,  0.00085033, ..., -0.04621635,\n",
       "         0.02661492,  0.01559437],\n",
       "       [ 0.01609499, -0.00855552, -0.04493266, ...,  0.03480312,\n",
       "        -0.00547666,  0.02209163],\n",
       "       ...,\n",
       "       [ 0.04501486,  0.00680646, -0.02832668, ..., -0.02044657,\n",
       "         0.00333674,  0.01614696],\n",
       "       [-0.0446874 , -0.01877555,  0.0362463 , ...,  0.03446983,\n",
       "         0.00546066,  0.04753338],\n",
       "       [-0.04842912, -0.01314162, -0.01903698, ..., -0.03364668,\n",
       "        -0.04321274,  0.02449815]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Embedding layer weights using get_weights()\n",
    "embedding_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04178005,  0.00520136,  0.0089943 , -0.04205627,  0.04231781,\n",
       "       -0.02851737,  0.02061622,  0.03990252,  0.02662443,  0.02833611,\n",
       "        0.04308758, -0.01404224, -0.02492284, -0.00248582, -0.03672264,\n",
       "        0.03104668], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the 14th index\n",
    "embedding_layer.get_weights()[0][14,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a layer that uses the mask_zero kwarg\n",
    "\n",
    "masking_embedding_layer=tf.keras.layers.Embedding(input_dim=501,output_dim=16,mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=63, shape=(1, 4, 1), dtype=bool, numpy=\n",
       "array([[[False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply this layer to the sequence and see the _keras_mask property\n",
    "\n",
    "masked_sequences_of_embeddings=masking_embedding_layer(sequence_of_indices)\n",
    "masked_sequences_of_embeddings._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Embedding Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)=get_and_pad_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index\n",
    "imdb_word_index=get_imdb_word_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the keys and values of the word index\n",
    "\n",
    "inv_word_index={value:key for key,value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'and',\n",
       " 'have',\n",
       " 'everything',\n",
       " 'that',\n",
       " \"he's\",\n",
       " 'made',\n",
       " 'on',\n",
       " 'dvd',\n",
       " 'except',\n",
       " 'for',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'the',\n",
       " '2',\n",
       " 'hour',\n",
       " 'twin',\n",
       " 'peaks',\n",
       " 'movie',\n",
       " 'so',\n",
       " 'when',\n",
       " 'i',\n",
       " 'found',\n",
       " 'out',\n",
       " 'about',\n",
       " 'this',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'grabbed',\n",
       " 'it',\n",
       " 'and',\n",
       " 'and',\n",
       " 'what',\n",
       " 'is',\n",
       " 'this',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'drawn',\n",
       " 'black',\n",
       " 'and',\n",
       " 'white',\n",
       " 'cartoons',\n",
       " 'that',\n",
       " 'are',\n",
       " 'loud',\n",
       " 'and',\n",
       " 'foul',\n",
       " 'mouthed',\n",
       " 'and',\n",
       " 'unfunny',\n",
       " 'maybe',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " \"what's\",\n",
       " 'good',\n",
       " 'but',\n",
       " 'maybe',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'crap',\n",
       " 'that',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'public',\n",
       " 'under',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'few',\n",
       " 'bucks',\n",
       " 'too',\n",
       " 'let',\n",
       " 'me',\n",
       " 'make',\n",
       " 'it',\n",
       " 'clear',\n",
       " 'that',\n",
       " 'i',\n",
       " \"didn't\",\n",
       " 'care',\n",
       " 'about',\n",
       " 'the',\n",
       " 'foul',\n",
       " 'language',\n",
       " 'part',\n",
       " 'but',\n",
       " 'had',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'because',\n",
       " 'my',\n",
       " 'neighbors',\n",
       " 'might',\n",
       " 'have',\n",
       " 'all',\n",
       " 'in',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'highly',\n",
       " 'disappointing',\n",
       " 'release',\n",
       " 'and',\n",
       " 'may',\n",
       " 'well',\n",
       " 'have',\n",
       " 'just',\n",
       " 'been',\n",
       " 'left',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " 'set',\n",
       " 'as',\n",
       " 'a',\n",
       " 'curiosity',\n",
       " 'i',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'you',\n",
       " \"don't\",\n",
       " 'spend',\n",
       " 'your',\n",
       " 'money',\n",
       " 'on',\n",
       " 'this',\n",
       " '2',\n",
       " 'out',\n",
       " 'of',\n",
       " '10']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first dataset example sentence\n",
    "[inv_word_index[index] for index in x_train[100] if index > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an Embedding layer into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum token value\n",
    "max_index_value=max(imdb_word_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an embedding dimension\n",
    "embedding_dim=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using Sequential:\n",
    "#     1. Embedding layer\n",
    "#     2. GlobalAveragePooling1D\n",
    "#     3. Dense\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1,output_dim=embedding_dim,mask_zero=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API refresher: use the Model to build the same model\n",
    "\n",
    "review_sequences=tf.keras.Input((None,))\n",
    "embedding_sequence=tf.keras.layers.Embedding(input_dim=max_index_value+1,output_dim=embedding_dim,mask_zero=False)(review_sequences)\n",
    "average_embedding=tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "positive_probability=tf.keras.layers.Dense(1,activation='sigmoid')(average_embedding)\n",
    "model=tf.keras.Model(inputs=review_sequences,outputs=positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile, train, and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a binary cross-entropy loss\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.6695 - accuracy: 0.6819 - val_loss: 0.0166 - val_accuracy: 0.7484\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.6276 - accuracy: 0.7510 - val_loss: 0.0154 - val_accuracy: 0.7641\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.5768 - accuracy: 0.7941 - val_loss: 0.0142 - val_accuracy: 0.7719\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.5277 - accuracy: 0.8172 - val_loss: 0.0130 - val_accuracy: 0.8031\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.4845 - accuracy: 0.8359 - val_loss: 0.0121 - val_accuracy: 0.8078\n"
     ]
    }
   ],
   "source": [
    "# Train the model using .fit(), savng its history\n",
    "history=model.fit(x_train,y_train,batch_size=32,epochs=5,validation_data=(x_test,y_test),validation_steps=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The TensorFlow embedding projector\n",
    "\n",
    "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embedding layer's weights from the trained model\n",
    "\n",
    "weights=model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/vecs.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-07d4ece34681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mout_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vecs.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mout_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meta.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/vecs.tsv'"
     ]
    }
   ],
   "source": [
    "# Save the word Embeddings to tsv files\n",
    "# Two files: \n",
    "#     one contains the embedding labels (meta.tsv),\n",
    "#     one contains the embeddings (vecs.tsv)\n",
    "\n",
    "import io\n",
    "from os import path\n",
    "\n",
    "out_v = io.open(path.join('data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
    "out_m = io.open(path.join('data', 'meta.tsv'), 'w', encoding='utf-8')\n",
    "\n",
    "k = 0\n",
    "\n",
    "for word, token in word_index.items():\n",
    "    if k != 0:\n",
    "        out_m.write('\\n')\n",
    "        out_v.write('\\n')\n",
    "    \n",
    "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
    "    out_m.write(word)\n",
    "    k += 1\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()\n",
    "# beware large collections of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Recurrent neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and pass an input to a SimpleRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleRNN layer and test it\n",
    "simplernn_layer=tf.keras.layers.SimpleRNN(units=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=15825, shape=(1, 16), dtype=float32, numpy=\n",
       "array([[-1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         1., -1., -1.]], dtype=float32)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that only the final cell output is returned\n",
    "sequence=tf.constant([[[1.,1.],[2.,2.],[56.,-100.]]])\n",
    "layer_output=simplernn_layer(sequence)\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)=get_and_pad_imdb_dataset(maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "imdb_word_index=get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value\n",
    "max_index_value=max(imdb_word_index.values())\n",
    "embedding_dim=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build the model:\n",
    "# 1. Embedding.\n",
    "# 2. LSTM.\n",
    "# 3. Dense.\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1,output_dim=embedding_dim,mask_zero=True),\n",
    "    tf.keras.layers.LSTM(units=16),\n",
    "    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary cross-entropy loss\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 526s 21ms/sample - loss: 0.3950 - accuracy: 0.8155\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 475s 19ms/sample - loss: 0.2285 - accuracy: 0.9146\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 474s 19ms/sample - loss: 0.1829 - accuracy: 0.9338\n"
     ]
    }
   ],
   "source": [
    "# Fit the model and save its training history\n",
    "history=model.fit(x_train,y_train,epochs=3,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-0af8a260a212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and validation accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (3,) and (5,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "loss     = history_dict['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ignore',\n",
       " 'the',\n",
       " 'bad',\n",
       " 'reviews',\n",
       " 'on',\n",
       " 'here',\n",
       " 'this',\n",
       " 'film',\n",
       " 'is',\n",
       " 'awesome',\n",
       " 'just',\n",
       " 'before',\n",
       " 'dawn',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'example',\n",
       " 'of',\n",
       " 'what',\n",
       " 'can',\n",
       " 'be',\n",
       " 'done',\n",
       " 'in',\n",
       " 'a',\n",
       " 'film',\n",
       " 'with',\n",
       " 'a',\n",
       " 'minimal',\n",
       " 'budget',\n",
       " 'if',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'dedicated',\n",
       " 'crew',\n",
       " 'decent',\n",
       " 'script',\n",
       " 'and',\n",
       " 'a',\n",
       " 'cool',\n",
       " 'idea',\n",
       " 'for',\n",
       " 'a',\n",
       " 'film',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'hell',\n",
       " 'of',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'fun',\n",
       " 'br',\n",
       " 'br',\n",
       " 'i',\n",
       " 'enjoyed',\n",
       " 'it',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'more',\n",
       " 'than',\n",
       " 'most',\n",
       " 'other',\n",
       " \"80's\",\n",
       " 'slashers',\n",
       " 'because',\n",
       " 'the',\n",
       " 'killer',\n",
       " 'is',\n",
       " 'so',\n",
       " 'unique',\n",
       " 'wrong',\n",
       " 'turn',\n",
       " 'ripped',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'off',\n",
       " 'something',\n",
       " 'fierce',\n",
       " \"there's\",\n",
       " 'plenty',\n",
       " 'of',\n",
       " 'blood',\n",
       " 'and',\n",
       " 'scares',\n",
       " 'my',\n",
       " 'girlfriend',\n",
       " 'was',\n",
       " 'freaked',\n",
       " 'out',\n",
       " 'and',\n",
       " 'she',\n",
       " 'watches',\n",
       " 'almost',\n",
       " 'everything',\n",
       " 'with',\n",
       " 'me',\n",
       " 'and',\n",
       " \"doesn't\",\n",
       " \"it's\",\n",
       " 'got',\n",
       " 'that',\n",
       " 'creepiness',\n",
       " 'to',\n",
       " 'it',\n",
       " 'br',\n",
       " 'br',\n",
       " \"i'd\",\n",
       " 'say',\n",
       " 'that',\n",
       " 'just',\n",
       " 'before',\n",
       " 'dawn',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'early',\n",
       " \"80's\",\n",
       " 'slasher',\n",
       " 'out',\n",
       " 'there',\n",
       " 'i',\n",
       " 'really',\n",
       " 'enjoyed',\n",
       " 'it',\n",
       " 'br',\n",
       " 'br',\n",
       " '8',\n",
       " 'out',\n",
       " 'of',\n",
       " '10',\n",
       " 'kids']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first test data example sentence\n",
    "# (invert the word index)\n",
    "\n",
    "inv_imdb_word_index={value:key for key,value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_test[0] if index >2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9881066]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model prediction using model.predict()\n",
    "model.predict(x_test[None,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the corresponding label\n",
    "y_test[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_6\"></a>\n",
    "## Stacked RNNs and the Bidirectional wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)=get_and_pad_imdb_dataset(num_words=5000,maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "imdb_word_index=get_imdb_word_index(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build stacked and bidirectional recurrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value and specify an embedding dimension\n",
    "max_index_value=max(imdb_word_index.values())\n",
    "embedding_dim=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1,output_dim=embedding_dim,mask_zero=True),\n",
    "    tf.keras.layers.LSTM(32,return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32,return_sequences=False),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1,output_dim=embedding_dim,mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8),\n",
    "                                  merge_mode='sum',\n",
    "                                 backward_layer=tf.keras.layers.GRU(units=8,go_backwards=True)),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1,output_dim=embedding_dim,mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8,return_sequences=True),merge_mode='concat'),\n",
    "    tf.keras.layers.GRU(units=8,return_sequences=False),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      " 1216/25000 [>.............................] - ETA: 31:12 - loss: 0.6931 - accuracy: 0.5041"
     ]
    }
   ],
   "source": [
    "# Train the model, saving its history\n",
    "history=model.fit(x_train,y_train,epochs=3,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
